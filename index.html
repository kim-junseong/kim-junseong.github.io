<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta name="google-site-verification" content="xDNWUvx6Q5EWK5YYSyKvK8DZTmvXhKsGX203Ll-BFFE" >
    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
    <title>Kim Junseong</title>
    <link rel="stylesheet" type="text/css" id="defaultstyle" href="./style.css"/>
    <script type="text/javascript" src="js/tracker.js"></script>
    <script type="text/javascript" src="js/pageturner.js"></script>
  </head>
  <script src="script/functions.js"></script>
  <body>
    <div class="container">

      <div class="intro">

        <h1>Kim Junseong</h1>
        <img src="media/profile_240713.png" width="224" alt="Kim Junseong"/>
        <p>
            I am a joint MS-Ph.D. student at <a href="https://ami.postech.ac.kr/">AMILab</a> in Electrical Engineering at <a href="https://postech.ac.kr/eng">POSTECH</a>, advised by <a href="https://ami.postech.ac.kr/members/tae-hyun-oh">Tae-Hyun Oh</a>.
            Previously, I completed my B.S. in Electrical Engineering at POSTECH.
        </p>
        <p>
            I work on research projects at the intersection of computer graphics, vision, and machine learning.
            My research lies in 3D machine perception including, 3D Reconstruction, Neural rendering, and Computational Photography, but not limited to.
        </p>
        <p>
          <a class="a_more" href="mailto:junseong.kim@postech.ac.kr">junseong.kim@postech.ac.kr</a> |
          <a class="a_more" href="https://www.overleaf.com/read/hcphxhfygpks">CV</a> |
          <a class="a_more" href="https://scholar.google.co.kr/citations?user=CMqYPY8AAAAJ&hl=ko">Google Scholar</a> |
          <a class="a_more" href="https://github.com/gucka28">GitHub</a>
        </p>

      </div> <!-- intro -->

      <h2>News</h2>
          <div class="custom-bullet"><b>05/2025</b> I am selected as an outstanding reviewer <span style="color: red;">(top 5.64%)</span> at CVPR 2025.</div>
          <div class="custom-bullet"><b>02/2025</b> Our paper <a href="https://drsplat.github.io/"> Dr.Splat </a> is accepted for Highlight at CVPR 2025 <span style="color: red;">(highlight Top 3.7%)</span>.</div>
          <div class="custom-bullet"><b>01/2025</b> Our paper <a href="https://facthash.github.io/"> FactHash </a> is accepted for presentation at ICRA 2025.</div>
          <div class="custom-bullet"><b>01/2025</b> I started research scientist internship at <a href="https://www.noahlab.com.hk/#/about"> Huawei Noah’s Ark Lab 3D Imaging Team </a>. </div>
          <div class="custom-bullet"><b>12/2024</b> Our paper <a href="https://soundbrush.github.io/"> SoundBrush </a> is accepted to AAAI 2024.</div>
          <!--                show more toggle button-->
          <a class="a_more" href="javascript:toggleblock(&#39;old_news&#39;)">---- show more ----</a>
          <div id="old_news" style="display: none;">
            <div class="custom-bullet"><b>08/2024</b> Our paper <a href="https://facthash.github.io/"> FactHash </a> is accepted to RA-L.</div>
            <div class="custom-bullet"><b>07/2024</b> Our paper <a href="https://axial-momag.github.io/axial-momag/"> Axial Motion magnification</a> is accepted to ECCV 2024.</div>
            <div class="custom-bullet"><b>05/2024</b> Our paper <a href="https://mingyukim87.github.io/SynergyNeRF/"> SynergyNeRF </a> is accepted to ICML 2024.</div>
            <div class="custom-bullet"><b>02/2024</b> I am starting Academic collaboration with NVIDIA Taiwan. </div>
            <div class="custom-bullet"><b>04/2023</b> Our paper on deep motion magnification is accepted to CVPRW 2023. </div>
            <div class="custom-bullet"><b>03/2023</b> Invited to give a talk on HDR-Plenoxels at NAVER. </div>
            <div class="custom-bullet"><b>01/2023</b> I am joining 3D NeRF team of Naver AI Lab as a Research Intern. </div>
            <div class="custom-bullet"><b>07/2022</b> Our paper <a href="https://hdr-plenoxels.github.io/">HDR-Plenoxels</a> is accepted to ECCV 2022.</div>              
          </div>

        <h2>Research Experiences</h2>
            <div class="list-item custom-bullet"><b>Huawei Noah’s Ark Lab 3D Imaging Team</b>, London.<span style="float: right;">Jan 2025 - present</span><br>
              &nbsp&nbsp Research Intern, working with <a href="https://perezpellitero.github.io/">Eduardo Pérez Pellitero</a>.<br/>
            </div>
            <div class="list-item custom-bullet"><b>NVIDIA Research Taiwan</b>, Taiwan.<span style="float: right;">Feb 2024 - present</span><br>
                &nbsp&nbsp Academic Collaboration, working with <a href="https://research.nvidia.com/person/jaesung-choe">jaesung-choe</a>.<br/>
            </div>
            <div class="list-item custom-bullet"><b>Naver AI lab - 3D NeRF team</b>, South Korea.<span style="float: right;">Feb 2023 - Aug 2023</span><br>
                &nbsp&nbsp Research Intern, worked with <a href="https://wityworks.com/">Jin-Hwa Kim</a>.<br/>
            </div>
            <div class="list-item custom-bullet"><b>POSTECH - Algorithmic Machine Intelligence lab</b>, Pohang, Korea.<span style="float: right;">Sep 2021 - Present</span><br>
                &nbsp&nbsp Graduate Student, working with <a href="https://ami.postech.ac.kr/members/tae-hyun-oh">Tae-Hyun Oh</a>.<br/>
            </div>

      <h2>Publications</h2>

      <div class="item">
        <img src='./media/cvpr25.png' width="192" />
        <p>
          <b> Dr. Splat: Directly Referring 3D Gaussian Splatting via Direct Language Embedding Registration</b><br/>
          <u>Kim Jun-Seong</u>, GeonU Kim, Kim Yu-Ji, Yu-Chiang Frank Wang, Jaesung Choe†, Tae-Hyun Oh†<br/>
          <i> CVPR, 2025 <span style="color: red;">(highlight Top 3.7%)</span> </i><br/>
          <a href="https://drsplat.github.io/">Project page</a> |
          <a href="https://arxiv.org/abs/2502.16652">Paper</a> |
        </p>
      </div>

      <div class="item">
        <img src='./media/soundbrush.png' width="192" />
        <p>
          <b> SoundBrush: Sound as a Brush for Visual Scene Editing</b><br/>
          Kim Sung-Bin, <u>Kim Jun-Seong</u>, Junseok Ko, Yewon Kim, Tae-Hyun Oh<br/>
          <i> AAAI, 2025 </i><br/>
          <a href="https://soundbrush.github.io/">Project page</a> |
          <a href="https://arxiv.org/abs/2501.00645">Paper</a> |
        </p>
      </div>

      <div class="item">
        <img src='./media/ral24.png' width="192" />
        <p>
          <b>Factorized Multi-Resolution HashGrid for Efficient Neural Radiance Fields: Execution on Edge-Devices</b><br/>
          <u>Kim Jun-Seong</u>*, Mingyu Kim*, GeonU Kim, Tae-Hyun Oh, Jin-Hwa Kim<br/>
          <i> RA-L, 2024 </i><br/>
          <note>- Presented in ICRA, 2025, Atlanta </note><br/>
          <a href="https://axial-momag.github.io/axial-momag/">Project page</a> |
          <a href="https://arxiv.org/abs/2312.09551">Paper</a> |
        </p>
      </div>

      <div class="item">
        <img src='./media/eccv24.gif' width="192" />
        <p>
          <b>Learning-based Axial Motion Magnification</b><br/>
          Kwon Byung-Ki, Oh Hyun-Bin, <u>Kim Jun-Seong</u>, Hyunwoo Ha, Tae-Hyun Oh<br/>
          <i>ECCV 2024</i><br/>
            <a href="https://axial-momag.github.io/axial-momag/">Project page</a> |
            <a href="https://arxiv.org/abs/2312.09551">Paper</a> |
        </p>
      </div>

      <div class="item">
        <img src='./media/icml24.png' width="192" />
        <p>
        <b>Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs</b><br/>
        Mingyu Kim, <u>Kim Jun-Seong</u>, Se-Young Yun, Jin-Hwa Kim <br/>
            <i>ICML 2024</i><br/>
            <a href="https://mingyukim87.github.io/SynergyNeRF/">Project page</a> |
            <a href="https://arxiv.org/abs/2405.07857">Paper</a>
      
      <div class="item">
        <img src='./media/tog.png' width="192" />
        <p>
          <b>Revisiting Learning-based Video Motion Magnification for Real time processing</b><br/>
          Hyunwoo Ha, Oh Hyun-Bin, <u>Kim Jun-Seong</u>, Kwon Byung-Ki, Kim Sung-Bin, Linh-Tam Tran, Ji-Yun Kim, Sung-Ho Bae, Tae-Hyun Oh<br/>
          <i>Arxiv preprint 2024</i><br/>
            <a href="https://arxiv.org/abs/2403.01898">Paper</a>
        </p>
      </div>

      </div>
      <div class="item">
        <img src='./media/hdr.gif' width="192" />
        <p>
        <b>HDR-Plenoxels: Self-Calibrating High Dynamic Range Radiance Fields</b><br/>
        <u>Kim Jun-Seong*</u>, Kim Yu-Ji*, Moon Ye-Bin, Tae-Hyun Oh<br/>
            <i>ECCV 2022</i><br/>
            <a href="https://hdr-plenoxels.github.io/">Project page</a> |
            <a href="https://arxiv.org/abs/2208.06787">Paper</a> |
            <a href="https://www.youtube.com/watch?v=LgZkVxgbOII&list=PLRg-WgV5P2lnv2JIo-RyhNPjlGD3aVmLj&index=5">Video</a><br/>
            <note>- Presented in Learning 3D with Multi-View Supervision Workshop (3DMV) at CVPR 2023 </note>
        </p>
      </div>

      <h2>Awards and Honors</h2>
        <ul>
          <li> CVPR 2025 Outstanding Reviewer </li>
          <li> (Domestic) IPIU2025 Outstanding Poster Presentation Awards </li>
          <li> (Domestic) IPIU2023 Best Paper Award </li>
        </ul>

      <h2>Academic Services</h2>
        <ul>
          <li> IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) [Outstanding Reviewer in 2025]
          <li> IEEE/CVF International Conference on Computer Vision (ICCV)
          <li> European Conference on Computer Vision (ECCV)
          <li> Advances in Neural Information Processing Systems (NeurIPS)

      <div class="outro">
        template adapted from <a href="https://changilkim.com/">this website</a>
      </div>

    </div> <!-- container -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-5RW688RKHW"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-5RW688RKHW');
    </script>
  </body>
</html>
