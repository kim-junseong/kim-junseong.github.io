<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta name="google-site-verification" content="xDNWUvx6Q5EWK5YYSyKvK8DZTmvXhKsGX203Ll-BFFE" >
    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
    <title>Kim Junseong</title>
    <link rel="stylesheet" type="text/css" id="defaultstyle" href="./style.css"/>
    <script type="text/javascript" src="js/tracker.js"></script>
    <script type="text/javascript" src="js/pageturner.js"></script>
  </head>
  <script src="script/functions.js"></script>
  <body>
    <div class="container">

      <div class="intro">

        <h1>Kim Junseong</h1>
        <img src="media/profile_240713.png" width="224" alt="Kim Junseong"/>
        <p>
            I am a Ph.D. student at <a href="https://ami.postech.ac.kr/">AMILab</a> in Electrical Engineering at <a href="https://postech.ac.kr/eng">POSTECH</a>, advised by <a href="https://ami.postech.ac.kr/members/tae-hyun-oh">Tae-Hyun Oh</a>.
            Previously, I was a research scientist intern at researcher at <a href="https://virtualhumans.mpi-inf.mpg.de/">Real Virtual Humans Group</a> at the <a href="https://uni-tuebingen.de/">Univ. of Tübingen</a>, working with <a href="https://virtualhumans.mpi-inf.mpg.de/people/pons-moll.html">Gerard Pons-Moll</a>.
        </p>
        <p>
          My reseatch lies in 3D machine perception including, 3D Reconstruction, Neural rendering, and Computational Photography, but not limited to.
          <!--            During my bachelor, I spent a semester at <a href="https://www.ntu.edu.sg/">Nanyang Technological University (NTU)</a> as an exchange student.-->
        </p>
        <p>
          <a class="a_more" href="mailto:junseong.kim@postech.ac.kr">junseong.kim@postech.ac.kr</a> |
          <a class="a_more" href="https://www.overleaf.com/read/hcphxhfygpks">CV</a> |
          <a class="a_more" href="https://scholar.google.co.kr/citations?user=CMqYPY8AAAAJ&hl=ko">Google Scholar</a> |
          <a class="a_more" href="https://github.com/gucka28">GitHub</a>
        </p>

      </div> <!-- intro -->

      <h2>News</h2>
          <div class="custom-bullet"><b>10/2024 <span style="color:#BB2222;">(New!)</span></b> I'll be joining <a href="https://about.meta.com/realitylabs/codecavatars/?utm_source=about.facebook.com&utm_medium=redirect">Meta Reality Labs - Codec Avatars team</a> as a research scientist intern. </div>
          <div class="custom-bullet"><b>02/2024</b> Our paper on <a href="https://arxiv.org/abs/2312.11360">text-driven PBR texture synthesis</a> is accepted to CVPR 2024.</div>
          <div class="custom-bullet"><b>12/2023</b> Our paper on efficient 3D scene stylization is accepted to AAAI 2024. </div>
          <div class="custom-bullet"><b>11/2023</b> I won the Grand Prize (1st place, Minister's award, $12,000) at ICT paper awards. </div>
          <div class="custom-bullet"><b>10/2023</b> I am selected as an <a href="https://ami.postech.ac.kr/57da3912-6dc3-41a1-b355-f010231a1756">outstanding reviewer</a> for ICCV 2023. </div>
          <div class="custom-bullet"><b>10/2023</b> I am joining <a href="https://virtualhumans.mpi-inf.mpg.de/">Real Virtual Humans Group</a> as a visiting Ph.D. student. </div>
  <!--                show more toggle button-->
          <a class="a_more" href="javascript:toggleblock(&#39;old_news&#39;)">---- show more ----</a>
          <div id="old_news" style="display: none;">
            <div class="custom-bullet"><b>08/2023</b> Our paper on text-driven human avatar generation is accepted to ICCVW 2023. </div>
            <div class="custom-bullet"><b>04/2023</b> Our paper on 3D face mesh recon. on videos is accepted to CVPRW 2023. </div>
            <div class="custom-bullet"><b>02/2023</b> Invited to give a talk on text-driven 4D human avatars at <a href="http://innerverz.io/">INNERVERZ</a>. </div>
            <div class="custom-bullet"><b>01/2023</b> Our <a href="https://link.springer.com/article/10.1007/s00371-023-02798-x">paper</a> on lightweight body mesh recon. is accepted to TVCJ 2023. </div>
            <div class="custom-bullet"><b>11/2022</b> Our paper <a href="https://clip-actor.github.io">CLIP-Actor</a> is selected as the winner of <a href="https://www.qualcomm.com/research/university-relations/innovation-fellowship/2022-south-korea">Qualcomm Innovation Fellowship Korea</a>!</div>
            <div class="custom-bullet"><b>07/2022</b> Our two papers, <a href="https://clip-actor.github.io">CLIP-Actor</a> and <a href="https://fastmetro.github.io">FastMETRO</a>, are accepted to ECCV 2022.</div>
            <div class="custom-bullet"><b>04/2022</b> I got accepted to <a href="https://iplab.dmi.unict.it/icvss2022/">ICVSS 2022</a>, and I will visit Sicily, Italy this summer. </div>
            <div class="custom-bullet"><b>10/2021</b> Our paper <a href="https://demr.github.io">DeMR</a> is accepted to BMVC 2021.</div>
          </div>

        <h2>Research Experiences</h2>
            <div class="list-item custom-bullet"><b>NVIDIA Research Taiwan</b>, Taiwan.<span style="float: right;">Feb 2024 - Present</span><br>
                &nbsp&nbsp Academic Collaboration, working with <a href="https://research.nvidia.com/person/jaesung-choe">jaesung-choe</a>, and <a href="https://www.linkedin.com/in/jovan-cmu/">Jovan Popović</a>.<br/>
            </div>
            <div class="list-item custom-bullet"><b>Naver AI lab - 3D NeRF team</b>, South Korea.<span style="float: right;">Feb 2023 - Aug 2023</span><br>
                &nbsp&nbsp Research Intern, worked with <a href="https://wityworks.com/">Jin-Hwa Kim</a>.<br/>
            </div>
            <div class="list-item custom-bullet"><b>POSTECH - Algorithmic Machine Intelligence lab</b>, Pohang, Korea.<span style="float: right;">Sep 2021 - Present</span><br>
                &nbsp&nbsp Graduate Student, working with <a href="https://ami.postech.ac.kr/members/tae-hyun-oh">Tae-Hyun Oh</a>.<br/>
            </div>

- Research Collaboration with NVIDIA Taiwan (2024.02)

      <h2>Publications</h2>

      <div class="item">
        <img src='./media/eccv24.gif' width="192" />
        <p>
          <b>Learning-based Axial Motion Magnification</b><br/>
          Kwon Byung-Ki, Oh Hyun-Bin, <u>Kim Jun-Seong</u>, Hyunwoo Ha, Tae-Hyun Oh<br/>
          <i>ECCV 2024</i><br/>
            <a href="https://axial-momag.github.io/axial-momag/">Project page</a> |
            <a href="https://arxiv.org/abs/2312.09551">Paper</a> |
        </p>
      </div>

      <div class="item">
        <img src='./media/ral24.png' width="192" />
        <p>
          <b>Factorized Multi-Resolution HashGrid for Efficient Neural Radiance Fields: Execution on Edge-Devices</b><br/>
          <u>Kim Jun-Seong</u>*, Mingyu Kim*, GeonU Kim, Tae-Hyun Oh, Jin-Hwa Kim<br/>
          <i> Under review</i><br/>
        </p>
      </div>

      <div class="item">
        <img src='./media/icml24.png' width="192" />
        <p>
        <b>Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs</b><br/>
        Mingyu Kim, <u>Kim Jun-Seong</u>, Se-Young Yun, Jin-Hwa Kim <br/>
            <i>ICML 2024</i><br/>
            <a href="https://mingyukim87.github.io/SynergyNeRF/">Project page</a> |
            <a href="https://arxiv.org/abs/2405.07857">Paper</a>
      
      <div class="item">
        <img src='./media/tog.png' width="192" />
        <p>
          <b>Revisiting Learning-based Video Motion Magnification for Real time processing</b><br/>
          Hyunwoo Ha, Oh Hyun-Bin, <u>Kim Jun-Seong</u>, Kwon Byung-Ki, Kim Sung-Bin, Linh-Tam Tran, Ji-Yun Kim, Sung-Ho Bae, Tae-Hyun Oh<br/>
          <i>Arxiv preprint 2024</i><br/>
            <a href="https://arxiv.org/abs/2403.01898">Paper</a>
        </p>
      </div>

      </div>
      <div class="item">
        <img src='./media/hdr.gif' width="192" />
        <p>
        <b>HDR-Plenoxels: Self-Calibrating High Dynamic Range Radiance Fields</b><br/>
        <u>Kim Jun-Seong*</u>, Kim Yu-Ji*, Moon Ye-Bin, Tae-Hyun Oh<br/>
            <i>ECCV 2022</i><br/>
            <a href="https://hdr-plenoxels.github.io/">Project page</a> |
            <a href="https://arxiv.org/abs/2208.06787">Paper</a> |
            <a href="https://www.youtube.com/watch?v=LgZkVxgbOII&list=PLRg-WgV5P2lnv2JIo-RyhNPjlGD3aVmLj&index=5">Video</a>
            <note>- Presented in Learning 3D with Multi-View Supervision Workshop (3DMV) at CVPR 2023 </note>
        </p>
      </div>

      <h2>Invited Talks</h2>
        <ul>
          <li> HDR-Plenoxels: High Dynamic Range Radiance Fields, NAVER, Korea, 2023</li>
        </ul>

      <h2>Academic Services</h2>
        <ul>
          <li> Conference Reviewer: ICCV (2023), CVPR (2024), ECCV (2024)<br/>
          <li> Workshop Reviewer : Neural Fields @ ICLR (2023)
        </ul>

      <div class="outro">
        template adapted from <a href="https://changilkim.com/">this website</a>
      </div>

    </div> <!-- container -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-5RW688RKHW"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-5RW688RKHW');
    </script>
  </body>
</html>
